{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"kPt5q27L5557"},"source":["# CSE 547 - Colab 1\n","## Wordcount in Spark\n","\n","Adapted From Stanford CS246"]},{"cell_type":"markdown","metadata":{"id":"p0-YhEpP_Ds-"},"source":["### Setup"]},{"cell_type":"markdown","metadata":{"id":"Zsj5WYpR9QId"},"source":["Let's setup Spark on your Colab environment.  Run the cell below!"]},{"cell_type":"code","metadata":{"id":"k-qHai2252mI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698250322266,"user_tz":420,"elapsed":73229,"user":{"displayName":"Inna Wanyin Lin","userId":"07061680773764900373"}},"outputId":"e75a382f-2759-4a9c-c1b4-47abace31c56"},"source":["!pip install pyspark\n","!pip install -U -q PyDrive\n","!apt install openjdk-8-jdk-headless -qq\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=70a68f12a2354cd010e46bda3303132e9c458d54746b17d0120c0fe5f43b908a\n","  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.0\n","The following additional packages will be installed:\n","  libxtst6 openjdk-8-jre-headless\n","Suggested packages:\n","  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n","  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n","The following NEW packages will be installed:\n","  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n","0 upgraded, 3 newly installed, 0 to remove and 18 not upgraded.\n","Need to get 39.7 MB of archives.\n","After this operation, 144 MB of additional disk space will be used.\n","Selecting previously unselected package libxtst6:amd64.\n","(Reading database ... 120874 files and directories currently installed.)\n","Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n","Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n","Selecting previously unselected package openjdk-8-jre-headless:amd64.\n","Preparing to unpack .../openjdk-8-jre-headless_8u382-ga-1~22.04.1_amd64.deb ...\n","Unpacking openjdk-8-jre-headless:amd64 (8u382-ga-1~22.04.1) ...\n","Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n","Preparing to unpack .../openjdk-8-jdk-headless_8u382-ga-1~22.04.1_amd64.deb ...\n","Unpacking openjdk-8-jdk-headless:amd64 (8u382-ga-1~22.04.1) ...\n","Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n","Setting up openjdk-8-jre-headless:amd64 (8u382-ga-1~22.04.1) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n","Setting up openjdk-8-jdk-headless:amd64 (8u382-ga-1~22.04.1) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n","Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"-CJ71AKe91eh"},"source":["Now we authenticate a Google Drive client to download the file we will be processing in our Spark job.\n","\n","**Make sure to follow the interactive instructions.**"]},{"cell_type":"code","metadata":{"id":"5K93ABEy9Zlo"},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0orRvrc1-545"},"source":["id='1SE6k_0YukzGd5wK-E4i6mG83nydlfvSa'\n","downloaded = drive.CreateFile({'id': id})\n","downloaded.GetContentFile('pg100.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qwtlO4_m_LbQ"},"source":["If you executed the cells above, you should be able to see the file *pg100.txt* under the \"Files\" tab on the left panel."]},{"cell_type":"markdown","metadata":{"id":"CRaF2A_j_nC7"},"source":["### Your task"]},{"cell_type":"markdown","metadata":{"id":"ebLNUxP0_8x3"},"source":["If you run successfully the setup stage, you are ready to work on the *pg100.txt* file which contains a copy of the complete works of Shakespeare.\n","\n","Write a Spark application which outputs the number of words that start with each letter. This means that for every letter we want to count the total number of (non-unique) words that start with a specific letter. In your implementation **ignore the letter case**, i.e., consider all words as lower case. Also, you can ignore all the words **starting** with a non-alphabetic character.\n","\n","For this task we ask you to the [**RDD MapReduce API**](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.html) from spark (map, reduceByKey, flatMap, etc.) instead of **DataFrame API**."]},{"cell_type":"code","metadata":{"id":"xu-e7Ph2_ruG"},"source":["from pyspark.sql import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext\n","import pandas as pd\n","\n","# create the Spark Session\n","spark = SparkSession.builder.getOrCreate()\n","\n","# create the Spark Context\n","sc = spark.sparkContext"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuAxGFPFB43Y","executionInfo":{"status":"ok","timestamp":1636494251115,"user_tz":480,"elapsed":393,"user":{"displayName":"Mike Merrill","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgrOyH3WdicK4YSpmk9RvhIvzqPhEBW2pLYMQjs=s64","userId":"10699760013576947867"}},"outputId":"60498d94-0798-41d8-a81f-7e48d8daa62b","colab":{"base_uri":"https://localhost:8080/"}},"source":["1+1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"SIrXJyVNP2AI"},"source":["Once you obtained the desired results, **head over to Canvas and submit\n","your solution for this Colab**!"]},{"cell_type":"code","source":[],"metadata":{"id":"H_WlUN9ImrHZ"},"execution_count":null,"outputs":[]}]}
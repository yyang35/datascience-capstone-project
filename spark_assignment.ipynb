{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPt5q27L5557"
   },
   "source": [
    "# CSE 481DS - Spark Colab\n",
    "## Wordcount in Spark\n",
    "\n",
    "Adapted From Stanford CS246"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0-YhEpP_Ds-"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zsj5WYpR9QId"
   },
   "source": [
    "Let's setup Spark on your Colab environment.  Run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k-qHai2252mI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/sherryyang/anaconda3/lib/python3.11/site-packages (3.5.0)\r\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /Users/sherryyang/anaconda3/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install -U -q PyDrive\n",
    "#!apt install openjdk-8-jdk-headless -qq\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CJ71AKe91eh"
   },
   "source": [
    "Now we authenticate a Google Drive client to download the file we will be processing in our Spark job.\n",
    "\n",
    "**Make sure to follow the interactive instructions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5K93ABEy9Zlo"
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "unable to open database file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moauth2client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GoogleCredentials\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Authenticate and create the PyDrive client\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m auth\u001b[38;5;241m.\u001b[39mauthenticate_user()\n\u001b[1;32m      8\u001b[0m gauth \u001b[38;5;241m=\u001b[39m GoogleAuth()\n\u001b[1;32m      9\u001b[0m gauth\u001b[38;5;241m.\u001b[39mcredentials \u001b[38;5;241m=\u001b[39m GoogleCredentials\u001b[38;5;241m.\u001b[39mget_application_default()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/colab/auth.py:148\u001b[0m, in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[1;32m    147\u001b[0m   _gcloud_login()\n\u001b[0;32m--> 148\u001b[0m _install_adc()\n\u001b[1;32m    149\u001b[0m colab_tpu_addr \u001b[38;5;241m=\u001b[39m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOLAB_TPU_ADDR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOLAB_SKIP_AUTOMATIC_TPU_AUTH\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _os\u001b[38;5;241m.\u001b[39menviron \u001b[38;5;129;01mand\u001b[39;00m colab_tpu_addr:\n\u001b[1;32m    151\u001b[0m   \u001b[38;5;66;03m# If we've got a TPU attached, we want to run a TF operation to provide\u001b[39;00m\n\u001b[1;32m    152\u001b[0m   \u001b[38;5;66;03m# our new credentials to the TPU for GCS operations.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/colab/auth.py:108\u001b[0m, in \u001b[0;36m_install_adc\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Install the gcloud token as the Application Default Credential.\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m gcloud_db_path \u001b[38;5;241m=\u001b[39m _os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    107\u001b[0m     _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATALAB_ROOT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent/.config/credentials.db\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m db \u001b[38;5;241m=\u001b[39m _sqlite3\u001b[38;5;241m.\u001b[39mconnect(gcloud_db_path)\n\u001b[1;32m    109\u001b[0m c \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[1;32m    110\u001b[0m ls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(c\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSELECT * FROM credentials;\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mOperationalError\u001b[0m: unable to open database file"
     ]
    }
   ],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0orRvrc1-545"
   },
   "outputs": [],
   "source": [
    "id='158kRwe6PPT4kub20hR_FlV8qpZsdW_rm' # this file is in the course google drive with public visibility \n",
    "downloaded = drive.CreateFile({'id': id})\n",
    "downloaded.GetContentFile('pg100.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwtlO4_m_LbQ"
   },
   "source": [
    "If you executed the cells above, you should be able to see the file *pg100.txt* under the \"Files\" tab on the left panel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRaF2A_j_nC7"
   },
   "source": [
    "### Your task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebLNUxP0_8x3"
   },
   "source": [
    "If you run successfully the setup stage, you are ready to work on the *pg100.txt* file which contains a copy of the complete works of Shakespeare.\n",
    "\n",
    "Write a Spark application which outputs the number of words that start with each letter. This means that for every letter we want to count the total number of (non-unique) words that start with a specific letter. In your implementation **ignore the letter case**, i.e., consider all words as lower case. Also, you can ignore all the words **starting** with a non-alphabetic character.\n",
    "\n",
    "For this task we ask you to the [**RDD MapReduce API**](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) from spark (map, reduceByKey, flatMap, etc.) instead of **DataFrame API**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xu-e7Ph2_ruG"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext\n",
    "import pandas as pd\n",
    "\n",
    "# create the Spark Session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# create the Spark Context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AuAxGFPFB43Y"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIrXJyVNP2AI"
   },
   "source": [
    "Once you obtained the desired results, **head over to Canvas and submit your solution for this Colab**!\n",
    "\n",
    "Please paste your code and your results (word counts for each of the 26 letters) in some human-readable format (PDF or text file) and submit this to canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1pDavlAEDE0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Spark Word Count Colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

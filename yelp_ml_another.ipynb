{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"yelp_ml_master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "df['hours'] = df['hours'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith('{') and x.endswith('}') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attributes'] = df['attributes'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith('{') and x.endswith('}') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_minutes(time_str):\n",
    "    # Split the time string into hours and minutes\n",
    "    hours, minutes = map(int, time_str.split(':'))\n",
    "    # Convert hours to minutes and add to minutes\n",
    "    return hours * 60 + minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_time(row):\n",
    "    hours = row['hours']\n",
    "    total_time = []\n",
    "    for day, hour in hours.items():\n",
    "        str_list = hour.split('-')\n",
    "        time = time_to_minutes(str_list[1]) - time_to_minutes(str_list[0])\n",
    "        if time < 0:\n",
    "            time = time_to_minutes(str_list[1]) + 24 * 60 - time_to_minutes(str_list[0])\n",
    "        if time > 0 : total_time.append(time)\n",
    "    return np.mean(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean_time'] = df.apply(get_average_time, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_counts = df.groupby(['name']).size().reset_index(name='count')\n",
    "brand_counts.sort_values('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(brand_counts, on = 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Assuming 'df' is your DataFrame and it has a 'stars_y' column for ratings\n",
    "\n",
    "# Define a function to safely convert stringified lists to actual lists\n",
    "def string_to_list(string_list):\n",
    "    try:\n",
    "        return ast.literal_eval(string_list)\n",
    "    except ValueError:\n",
    "        # In case of an error, return an empty list\n",
    "        return []\n",
    "    except SyntaxError:\n",
    "        # Handle strings that are not in list format (e.g., single quotes missing)\n",
    "        return [string_list.strip(\"[]\").replace(\"'\", \"\").split(\", \")]\n",
    "\n",
    "# Apply the function to the entire 'categories_list' column\n",
    "df['categories_list'] = df['categories_list'].apply(string_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now, you can explode the 'categories_list' column\n",
    "exploded_df = df.explode('categories_list')\n",
    "\n",
    "# Group by the individual categories and calculate the mean rating and count\n",
    "category_stats = exploded_df.groupby('categories_list')['stars_y'].agg(['mean', 'count'])\n",
    "\n",
    "# Convert the Series with multi-level columns to a DataFrame if needed\n",
    "category_stats_df = category_stats.reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "category_stats_df.columns = ['Category', 'AverageRating', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_stats_df = category_stats_df[~category_stats_df['Category'].isin(['Restaurants', 'Restaurants\t', 'Food'])]\n",
    "category_stats_df = category_stats_df[~category_stats_df['Category'].str.strip().isin(['Restaurants', 'Food'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_stats_df = category_stats_df.sort_values('Count')\n",
    "category_stats_df = category_stats_df.tail(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_category = list(category_stats_df['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_set = {}\n",
    "\n",
    "for attribute in df.attributes:\n",
    "    if attribute is not None:\n",
    "        for key, value in attribute.items():\n",
    "            if key in attribute_set.keys() :\n",
    "                attribute_set[key].add(value)\n",
    "            else:\n",
    "                attribute_set[key] = set()\n",
    "                attribute_set[key].add(value)\n",
    "\n",
    "selected_attributes = []\n",
    "for key, value in attribute_set.items():\n",
    "    if len(value) <= 3 and 'True' in value:\n",
    "        selected_attributes.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to process a single row's attribute dictionary\n",
    "def process_attributes(attr_dict):\n",
    "    # Initialize the array with -1\n",
    "    attr_array = [0] * len(selected_attributes)\n",
    "    if attr_dict is None:\n",
    "        return attr_array\n",
    "    \n",
    "    for i, attr in enumerate(selected_attributes):\n",
    "        if attr in attr_dict:\n",
    "            attr_array[i] = 1 if attr_dict[attr] == 'True' else 0\n",
    "    \n",
    "    return attr_array\n",
    "\n",
    "# Apply the function to each row\n",
    "df['attribute_array'] = df['attributes'].apply(process_attributes)\n",
    "\n",
    "# Now df['attribute_array'] contains the desired arrays for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to process a single row's attribute dictionary\n",
    "def process_attributes(attr_dict):\n",
    "    # Initialize the array with -1\n",
    "    attr_array = [0] * len(selected_attributes)\n",
    "    if attr_dict is None:\n",
    "        return attr_array\n",
    "    \n",
    "    for i, attr in enumerate(selected_attributes):\n",
    "        if attr in attr_dict:\n",
    "            attr_array[i] = 1 if attr_dict[attr] == 'True' else 0\n",
    "    \n",
    "    return attr_array\n",
    "\n",
    "# Apply the function to each row\n",
    "df['attribute_array'] = df['attributes'].apply(process_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_category(c_set):\n",
    "    # Initialize the array with -1\n",
    "    attr_array = [0] * len(selected_category)\n",
    "    if c_set is None:\n",
    "        return attr_array\n",
    "    \n",
    "    for i in range(len(selected_category)):\n",
    "        if selected_category[i]  in c_set: \n",
    "            attr_array[i] = 1\n",
    "    \n",
    "    return attr_array\n",
    "\n",
    "# Apply the function to each row\n",
    "df['category_array'] = df['categories_list'].apply(process_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'count': 'brand_size'})\n",
    "df = df.rename(columns={'density': 'density_state'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['stars_y', 'stars_x', 'population_postal', 'density_postal', 'population_city', 'density_city', 'population_state', 'density_state', 'mean_time', 'brand_size', 'category_counts', 'category_array', 'attribute_array' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df_ml.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= ['category_counts']\n",
    "for col in cols:\n",
    "    df_ml[col] = df_ml[col].apply(lambda x: [int(i) for i in ast.literal_eval(x)] if isinstance(x, str) and x.startswith('[') and x.endswith(']') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['category_counts']\n",
    "\n",
    "for col_name in col_names:\n",
    "    mean_name, std_name, median_name, max_name, min_name = col_name + '_mean', col_name  + '_std', col_name  + '_median', col_name  + '_max', col_name + '_min'\n",
    "    df_ml[mean_name] = df_ml[col_name].apply(lambda counts: pd.Series(counts).mean() if len(counts) > 0 else None)\n",
    "    df_ml[std_name] = df_ml[col_name].apply(lambda counts: pd.Series(counts).std() if len(counts) > 0 else None)\n",
    "    df_ml[median_name] = df_ml[col_name].apply(lambda counts: pd.Series(counts).median() if len(counts) > 0 else None)\n",
    "    df_ml[max_name] = df_ml[col_name].apply(lambda counts: pd.Series(counts).max() if len(counts) > 0 else None)\n",
    "    df_ml[min_name] = df_ml[col_name].apply(lambda counts: pd.Series(counts).min() if len(counts) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df_ml.drop(['category_counts'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df_ml.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming df_ml is your DataFrame and all columns are numerical\n",
    "X = df_ml.drop(['stars_x','stars_y', 'attribute_array', 'category_array'], axis=1)  # Use all columns except 'stars'\n",
    "one_hot_attribute = np.array(df_ml['attribute_array'].tolist())\n",
    "one_hot_category = np.array(df_ml['category_array'].tolist())\n",
    "\n",
    "\n",
    "X = np.concatenate([one_hot_attribute,X], axis=1)\n",
    "X = np.concatenate([one_hot_category,X], axis=1)\n",
    "\n",
    "\n",
    "y = df_ml['stars_y']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply standardization to the features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_name = list(df_ml.drop(['stars_x','stars_y', 'attribute_array', 'category_array'], axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_attributes_p= []\n",
    "for element in selected_attributes:\n",
    "    selected_attributes_p.append(\"[Attribute] \"+ element)\n",
    "\n",
    "selected_category_p =[]\n",
    "for element in selected_category:\n",
    "    selected_category_p.append(\"[Category] \"+ element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_name =  selected_attributes_p + selected_category_p + arr_name\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coefficients = pd.DataFrame({\n",
    "    'Feature': arr_name,\n",
    "    'Coefficient': model.coef_\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coefficients.sort_values('Coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coefficients.to_csv(\"ml_coeff.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, len(arr_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(arr_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "X = df_ml.drop(['stars_x','stars_y', 'attribute_array', 'category_array'], axis=1)  # Use all columns except 'stars'\n",
    "one_hot_attribute = np.array(df_ml['attribute_array'].tolist())\n",
    "one_hot_category = np.array(df_ml['category_array'].tolist())\n",
    "\n",
    "# Example: Assuming col1, col2, col3 need degree 5 and the rest degree 2\n",
    "columns_degree_5 = [ 'mean_time', 'brand_size']\n",
    "columns_degree_2 = [col for col in X.columns if col not in columns_degree_5]\n",
    "\n",
    "# Creating polynomial features for degree 5\n",
    "poly_5 = PolynomialFeatures(degree=5)\n",
    "X_poly_5 = poly_5.fit_transform(df_ml[columns_degree_5])\n",
    "\n",
    "# Creating polynomial features for degree 2\n",
    "poly_2 = PolynomialFeatures(degree=2)\n",
    "X_poly_2 = poly_2.fit_transform(df_ml[columns_degree_2])\n",
    "\n",
    "# Combine the polynomial features\n",
    "X_poly_combined = np.concatenate([X_poly_5, X_poly_2], axis=1)\n",
    "\n",
    "# Concatenate with one_hot_encoded features\n",
    "X_final = np.concatenate([one_hot_attribute, one_hot_category, X_poly_combined], axis=1)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_final)\n",
    "\n",
    "y = df_ml['stars_y']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model and make predictions\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, y_train_real, y_test_real = train_test_split(X_scaled, df_ml['stars_x'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Initialize and train the model with L1 regularization\n",
    "lasso_model = Lasso(alpha=0.01)  # You can adjust the alpha parameter\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "lasso_predictions = lasso_model.predict(X_test)\n",
    "rounded_lasso_predictions = np.array([round(p) for p in lasso_predictions])\n",
    "mse = mean_squared_error(y_test, lasso_predictions)\n",
    "print(f\"Mean Squared Error with L1 Regularization: {mse}\")\n",
    "\n",
    "# Access model coefficients\n",
    "lasso_coefficients = lasso_model.coef_\n",
    "print(lasso_coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Initialize and train the model with L2 regularization\n",
    "ridge_model = Ridge(alpha=0.00001)  # You can adjust the alpha parameter\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "rounded_ridge_predictions = np.array([round(p) for p in ridge_predictions])\n",
    "mse = mean_squared_error(y_test, ridge_predictions)\n",
    "print(f\"Mean Squared Error with L2 Regularization: {mse}\")\n",
    "\n",
    "# Access model coefficients\n",
    "ridge_coefficients = ridge_model.coef_\n",
    "print(ridge_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Define a range of lambda values to test\n",
    "alpha_values = np.logspace(-4, 4, 100)  # For example, values from 0.0001 to 10000\n",
    "\n",
    "# Initialize RidgeCV\n",
    "ridge_cv = RidgeCV(alphas=alpha_values, store_cv_values=True)\n",
    "\n",
    "# Fit the model\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# Best lambda\n",
    "best_lambda = ridge_cv.alpha_\n",
    "print(f\"Best lambda: {best_lambda}\")\n",
    "\n",
    "# You can also access the mean squared errors for different alphas\n",
    "mse_values = np.mean(ridge_cv.cv_values_, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_nearest_half(number):\n",
    "    return round(number * 2) / 2\n",
    "\n",
    "rounded_predictions = np.array([round_to_nearest_half(p) for p in ridge_predictions]) \n",
    "correct_predictions = (y_test_real == rounded_predictions)\n",
    "correctness_ratio = correct_predictions.mean()\n",
    "print(f\"Correctness Ratio: {correctness_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.to_csv(\"final_ml_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(predictions, y_test, s= 5, alpha=0.3)\n",
    "\n",
    "x = [0, 5]\n",
    "y = [0, 5]\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(x, y, color = \"red\")\n",
    "\n",
    "plt.ylabel('Real Avg.Rating')\n",
    "plt.xlabel('Predicted Avg.Rating')\n",
    "\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, color='gray')\n",
    "\n",
    "\n",
    "plt.ylim(0,5)\n",
    "plt.xlim(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(ridge_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test_real,ridge_predictions, s= 5, alpha=0.1)\n",
    "plt.ylim(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_counts.to_csv(\"yelp_brands.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rounded_predictions = np.array([round_to_nearest_half(p) for p in ridge_predictions]) \n",
    "correct_predictions = abs(y_test_real - predictions) <= 0.5\n",
    "correctness_ratio = correct_predictions.mean()\n",
    "print(f\"Correctness Ratio: {correctness_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse481",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
